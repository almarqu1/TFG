# DistilMatch: Sistema Interpretable de Adecuaci√≥n de Talento con LLMs

**Autor:** √Ålvaro Mart√≠nez Quilis  
**TFG - Grado en Ingenier√≠a Inform√°tica - ETSIINF (UPV)**  
**Fecha:** Septiembre 2025

[![Python](https://img.shields.io/badge/Python-3.11-3776AB.svg?style=flat&logo=python&logoColor=white)](https://www.python.org)
[![Hugging Face Transformers](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-PEFT-yellow)](https://huggingface.co/docs/peft/index)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit)](https://streamlit.io/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Version%20Control-blue?style=flat&logo=dvc)](https://dvc.org/)

---

## 1. Visi√≥n General del Proyecto

**DistilMatch** es un sistema avanzado de apoyo a la decisi√≥n para procesos de selecci√≥n de personal, desarrollado como Trabajo de Fin de Grado. El proyecto aborda las limitaciones de los *Applicant Tracking Systems* (ATS) tradicionales, que se basan en la coincidencia de palabras clave, proponiendo una soluci√≥n fundamentada en la **comprensi√≥n sem√°ntica profunda** del lenguaje natural.

El sistema utiliza un Gran Modelo de Lenguaje (LLM) especializado para evaluar la idoneidad entre un curr√≠culum y una oferta de empleo, proporcionando no solo una puntuaci√≥n num√©rica, sino tambi√©n una **justificaci√≥n razonada** de su decisi√≥n, aline√°ndose con los principios de la IA Explicable (XAI).

Este repositorio contiene todo el c√≥digo, los datos, el modelo entrenado y una demo interactiva para explorar y reproducir la investigaci√≥n.

## 2. Caracter√≠sticas Clave

La arquitectura de DistilMatch se basa en tecnolog√≠as de vanguardia para lograr un equilibrio entre rendimiento y eficiencia:

*   **üß† Destilaci√≥n de Conocimiento (Knowledge Distillation):** Un modelo *Teacher* de frontera (**Google Gemini 2.5 Pro**) transfiere su capacidad de razonamiento a un modelo *Student* mucho m√°s ligero y eficiente (**Qwen3-4B-Instruct**).
*   **‚ö° Ajuste Fino Eficiente (PEFT):** Se utiliza **LoRA (Low-Rank Adaptation)** junto con **cuantizaci√≥n de 4-bits** para entrenar el modelo *Student* en hardware de consumo (una √∫nica GPU con <16GB de VRAM), haciendo la investigaci√≥n accesible y reproducible.
*   **üîç Explicabilidad Inherente (Generative XAI):** A diferencia de m√©todos post-hoc, el modelo genera explicaciones textuales (fortalezas, debilidades, veredicto) como parte de su tarea principal, ofreciendo una transparencia total en su toma de decisiones.
*   **üí° El Descubrimiento Central: "Explanation-Tuning":** La investigaci√≥n demostr√≥ que entrenar al modelo para replicar el **razonamiento completo** del *Teacher* (no solo su puntuaci√≥n final) es significativamente m√°s efectivo, mejorando todas las m√©tricas de evaluaci√≥n.
*   **üß™ Demo Interactiva:** Una aplicaci√≥n desarrollada en **Streamlit** permite a cualquier usuario interactuar con el modelo final, probar sus capacidades con diferentes perfiles y ofertas, y visualizar su rendimiento en tiempo real.

## 3. Demo Interactiva en Streamlit

Para una exploraci√≥n pr√°ctica del sistema, puedes ejecutar la demo localmente. La aplicaci√≥n permite buscar en los datasets, seleccionar una oferta y una lista de candidatos, y obtener un ranking de compatibilidad detallado y justificado.

Para lanzar la aplicaci√≥n:
```bash
# Aseg√∫rate de tener el entorno virtual activado y las dependencias instaladas
streamlit run app.py
```

## 4. Estructura del Repositorio

El proyecto sigue una estructura MLOps para garantizar la modularidad y reproducibilidad:
```
TFG_DistilMatch/
‚îú‚îÄ‚îÄ config/              # Ficheros de configuraci√≥n (par√°metros, prompts)
‚îú‚îÄ‚îÄ data/                # Datos del proyecto (gestionados por DVC)
‚îú‚îÄ‚îÄ models/              # Adaptadores LoRA de cada exp. (gestionados por DVC)
‚îú‚îÄ‚îÄ notebooks/           # Notebooks para exploraci√≥n y an√°lisis cualitativo
‚îú‚îÄ‚îÄ outputs/             # Informes de evaluaci√≥n, ejemplos de explicabilidad
‚îú‚îÄ‚îÄ scripts/             # Scripts ejecutables (generaci√≥n de datos, evaluaci√≥n)
‚îú‚îÄ‚îÄ src/                 # C√≥digo fuente principal (l√≥gica de entrenamiento, utils)
‚îú‚îÄ‚îÄ app.py               # C√≥digo de la aplicaci√≥n de Streamlit
‚îú‚îÄ‚îÄ .dvc/                # Metadatos de DVC
‚îú‚îÄ‚îÄ dvc.yaml             # Definici√≥n del pipeline de MLOps
‚îî‚îÄ‚îÄ requirements.txt     # Dependencias de Python
```

## 5. Instalaci√≥n y Uso

### 5.1. Prerrequisitos
*   Python 3.10 o superior
*   Git y Git LFS
*   DVC (`pip install "dvc[gdrive]"` para usar Google Drive como remoto)

### 5.2. Pasos de Instalaci√≥n
1.  **Clona el repositorio:**
    ```bash
    git clone https://github.com/almarqu1/TFG
    cd TFG_DistilMatch
    ```

2.  **Crea y activa un entorno virtual:**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # macOS/Linux
    # .\.venv\Scripts\activate  # Windows
    ```

3.  **Instala las dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Descarga los datos y modelos con DVC:**
    ```bash
    dvc pull
    ```
    > NOTA: Por el momento, se ha optado por no emplear DVC. Los adaptadores se encuentran en la carpeta "distilmatch-v4-adapters" del repositorio.

5.  **Descarga los datasets de Kaggle:**
    *https://www.kaggle.com/datasets/saugataroyarghya/resume-dataset (Dataset CVs)
    *https://www.kaggle.com/datasets/arshkon/linkedin-job-postings
    > NOTA: aseg√∫rate de que tienes los archivos descargados en data/00_raw (necesitar√°s crear la carpeta) o de que tu config.yaml refleja la ubicaci√≥n de los datasets.

## 6. Resultados Clave

La estrategia de **Explanation-Tuning** (modelo `v4`) demostr√≥ una mejora sustancial sobre la capacidad *zero-shot* del modelo base, validando el √©xito de la destilaci√≥n de conocimiento.

| M√©trica de Evaluaci√≥n | Baseline (Student Zero-Shot) | Modelo Final (v4) | Mejora Relativa |
| :--- | :---: | :---: | :---: |
| **Error Absoluto Medio (MAE) ‚Üì** | 27.16 | **19.98** | -26.4% |
| **Correlaci√≥n de Spearman ($\rho$) ‚Üë** | 0.388 | **0.489** | +26.2% |
| **Exactitud Categ√≥rica ‚Üë** | 31.8% | **56.1%** | +76.4% |

La mejora en la **Correlaci√≥n de Spearman** es el resultado m√°s importante, ya que indica que el modelo final es significativamente mejor para **ordenar correctamente a los candidatos** de m√°s a menos id√≥neo, que es el objetivo principal de un sistema de preselecci√≥n.

## 7. Limitaciones y Trabajo Futuro
*   **Limitaciones:** El `Golden Set` fue anotado por un √∫nico experto. Los datasets est√°n en ingl√©s y centrados en el mercado de EEUU. Existe un riesgo potencial de heredar sesgos del modelo *Teacher*.
*   **Trabajo Futuro:**
    1.  **Auditor√≠a y Mitigaci√≥n de Sesgos (Fairness).**
    2.  **Implementaci√≥n de un ciclo de Aprendizaje Activo (*Human-in-the-loop*).**
    3.  **Especializaci√≥n por Dominios** mediante diferentes adaptadores LoRA.
    4.  **Expansi√≥n a arquitecturas multimodales** (ej. an√°lisis de repositorios de GitHub).
    5.  **Expansi√≥n de Golden Set y Silver Set con m√°s datos.**