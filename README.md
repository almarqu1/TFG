DistilMatch: Sistema Interpretable de Adecuaci√≥n de Talento con LLMs
Autor: √Ålvaro Mart√≠nez Quilis
TFG - Grado en Ingenier√≠a Inform√°tica - ETSINF (UPV)
Fecha: Septiembre 2025

Python
Hugging Face Transformers
PyTorch
Streamlit
DVC

1. Visi√≥n General del Proyecto
DistilMatch es un sistema avanzado de apoyo a la decisi√≥n para procesos de selecci√≥n de personal, desarrollado como Trabajo de Fin de Grado. El proyecto aborda las limitaciones de los Applicant Tracking Systems (ATS) tradicionales, que se basan en la coincidencia de palabras clave, proponiendo una soluci√≥n fundamentada en la comprensi√≥n sem√°ntica profunda del lenguaje natural.

El sistema utiliza un Gran Modelo de Lenguaje (LLM) especializado para evaluar la idoneidad entre un curr√≠culum y una oferta de empleo, proporcionando no solo una puntuaci√≥n num√©rica, sino tambi√©n una justificaci√≥n razonada de su decisi√≥n, aline√°ndose con los principios de la IA Explicable (XAI).

Este repositorio contiene todo el c√≥digo, los datos, los modelos entrenados y una demo interactiva para explorar y reproducir la investigaci√≥n.

2. Caracter√≠sticas Clave
La arquitectura de DistilMatch se basa en tecnolog√≠as de vanguardia para lograr un equilibrio entre rendimiento y eficiencia:

üß† Destilaci√≥n de Conocimiento (Knowledge Distillation): Un modelo Teacher de frontera (Google Gemini 2.5 Pro) transfiere su capacidad de razonamiento a un modelo Student mucho m√°s ligero y eficiente (Qwen3-4B-Instruct).
‚ö° Ajuste Fino Eficiente (PEFT): Se utiliza LoRA (Low-Rank Adaptation) junto con cuantizaci√≥n de 4-bits para entrenar el modelo Student en hardware de consumo (una √∫nica GPU con <16GB de VRAM), haciendo la investigaci√≥n accesible y reproducible.
üîç Explicabilidad Inherente (Generative XAI): A diferencia de m√©todos post-hoc como SHAP, el modelo genera explicaciones textuales (fortalezas, debilidades, potencial) como parte de su tarea principal, ofreciendo una transparencia total en su toma de decisiones.
üí° El Descubrimiento Central: "Explanation-Tuning": La investigaci√≥n demostr√≥ que entrenar al modelo para replicar el razonamiento completo del Teacher (no solo su puntuaci√≥n final) es significativamente m√°s efectivo, mejorando todas las m√©tricas de evaluaci√≥n.
üß™ Demo Interactiva: Una aplicaci√≥n desarrollada en Streamlit permite a cualquier usuario interactuar con el modelo final, probar sus capacidades con diferentes perfiles y ofertas, y visualizar su rendimiento en tiempo real.
3. Demo Interactiva en Streamlit
Para una exploraci√≥n pr√°ctica del sistema, puedes ejecutar la demo localmente. La aplicaci√≥n permite buscar en los datasets, seleccionar una oferta y una lista de candidatos, y obtener un ranking de compatibilidad detallado y justificado.

Demo de DistilMatch en Streamlit

Para lanzar la aplicaci√≥n:

bash
# Aseg√∫rate de tener el entorno virtual activado
streamlit run app.py
4. Estructura del Repositorio
El proyecto sigue una estructura MLOps para garantizar la modularidad y reproducibilidad:

text
TFG_DistilMatch/
‚îú‚îÄ‚îÄ config/              # Ficheros de configuraci√≥n (par√°metros, prompts)
‚îú‚îÄ‚îÄ data/                # Datos del proyecto (gestionados por DVC)
‚îú‚îÄ‚îÄ models/              # Adaptadores LoRA de cada exp. (gestionados por DVC)
‚îú‚îÄ‚îÄ notebooks/           # Notebooks para exploraci√≥n y an√°lisis cualitativo
‚îú‚îÄ‚îÄ outputs/             # Informes de evaluaci√≥n, ejemplos de explicabilidad
‚îú‚îÄ‚îÄ scripts/             # Scripts ejecutables (generaci√≥n de datos, evaluaci√≥n)
‚îú‚îÄ‚îÄ src/                 # C√≥digo fuente principal (l√≥gica de entrenamiento, utils)
‚îú‚îÄ‚îÄ app.py               # C√≥digo de la aplicaci√≥n de Streamlit
‚îú‚îÄ‚îÄ .dvc/                # Metadatos de DVC
‚îú‚îÄ‚îÄ dvc.yaml             # Definici√≥n del pipeline de MLOps
‚îî‚îÄ‚îÄ requirements.txt     # Dependencias de Python
5. Instalaci√≥n y Uso
5.1. Prerrequisitos
Python 3.10 o superior
Git y Git LFS
DVC (pip install dvc[s3])
5.2. Pasos de Instalaci√≥n
Clona el repositorio:

bash
git clone https://github.com/tu_usuario/tu_repositorio.git
cd TFG_DistilMatch
Crea y activa un entorno virtual:

bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
# .\.venv\Scripts\activate  # Windows
Instala las dependencias:

bash
pip install -r requirements.txt
Descarga los datos y modelos con DVC:

bash
dvc pull
Este comando descargar√° los datasets procesados y los adaptadores del modelo final.

5.3. Reproducir Experimentos
El pipeline est√° definido en dvc.yaml. Para reproducir el experimento de evaluaci√≥n del modelo final:

bash
# Este comando evaluar√° el checkpoint del modelo v4 contra el Golden Set
dvc repro evaluate_v4
Para ejecutar el entrenamiento de un experimento espec√≠fico (requiere una GPU configurada):

bash
# Ejemplo para lanzar el entrenamiento del experimento v4
python scripts/run_finetuning.py --experiment_id v4
6. Resultados Clave
La estrategia de Explanation-Tuning (modelo v4) demostr√≥ una mejora sustancial sobre la capacidad zero-shot del modelo base, validando el √©xito de la destilaci√≥n de conocimiento.

M√©trica de Evaluaci√≥n	Baseline (Student Zero-Shot)	Modelo Final (v4 - Explanation-Tuning)	Mejora
Error Absoluto Medio (MAE) ‚Üì	27.16	19.98	-26.4%
Correlaci√≥n de Spearman (
œÅ
œÅ) ‚Üë	0.388	0.489	+26.2%
Exactitud Categ√≥rica ‚Üë	31.8%	56.1%	+76.4%
La mejora en la Correlaci√≥n de Spearman es el resultado m√°s importante, ya que indica que el modelo final es significativamente mejor para ordenar correctamente a los candidatos de m√°s a menos id√≥neo, que es el objetivo principal de un sistema de preselecci√≥n.

7. Limitaciones y Trabajo Futuro
Limitaciones: El Golden Set fue anotado por un √∫nico experto. Los datasets est√°n en ingl√©s y centrados en el mercado de EEUU. Existe un riesgo potencial de heredar sesgos del modelo Teacher.
Trabajo Futuro:
Auditor√≠a y Mitigaci√≥n de Sesgos (Fairness).
Implementaci√≥n de un ciclo de Aprendizaje Activo (Human-in-the-loop).
Especializaci√≥n por Dominios mediante diferentes adaptadores LoRA.
Expansi√≥n a arquitecturas multimodales (ej. an√°lisis de repositorios de GitHub).