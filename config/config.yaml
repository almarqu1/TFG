# =================================================================
# FICHERO DE CONFIGURACIÓN GLOBAL DEL PROYECTO DISTILMATCH
# Centraliza todas las rutas, hiperparámetros y constantes para
# garantizar la reproducibilidad y facilitar la experimentación.
# =================================================================

# --- Parámetros Globales ---
global_seed: 42  # Semilla para todas las operaciones aleatorias (división de datos, muestreo).
                 # Fundamental para garantizar que los experimentos sean 100% reproducibles.

# --- Rutas del Pipeline de Datos (MLOps Staging) ---
# Estructura inspirada en las mejores prácticas de MLOps, separando los datos por su etapa
# de procesamiento para mantener un flujo de trabajo claro y versionable con DVC.
data_paths:
  # 00_raw: Datos originales, tal como se reciben. Son de solo lectura.
  raw:
    offers: "data/00_raw/datasetJobs2/postings.csv"
    job_skills: "data/00_raw/datasetJobs2/jobs/job_skills.csv"
    skills_map: "data/00_raw/datasetJobs2/mappings/skills.csv"
    job_industries: "data/00_raw/datasetJobs2/jobs/job_industries.csv"
    industries_map: "data/00_raw/datasetJobs2/mappings/industries.csv"
    cvs: "data/00_raw/datasetCV2/resume_data.csv"
  
  # 01_processed: Datos limpios y enriquecidos, listos para ser consumidos por los scripts.
  processed:
    offers: "data/01_processed/offers_processed.csv"
    cvs: "data/01_processed/cvs_processed.csv"
    # Este archivo contiene los pares aleatorios CV-Oferta que alimentarán al Teacher.
    unlabeled_pairs: "data/01_processed/unlabeled_pairs.csv"   
  
  # 02_intermediate: Artefactos generados que sirven como 'pegamento' entre etapas.
  intermediate:
    # El "Silver Set": un gran corpus de datos etiquetados por el Teacher (soft labels)
    # que se usará para el fine-tuning del modelo Student.
    silver_standard_train: "data/02_intermediate/silver_standard_train.jsonl"
  
  # 03_gold_standard: La "verdad absoluta" del proyecto. Curado manualmente por el experto.
  gold_standard:
    # El archivo de entrada completo, producto de la herramienta de curación.
    full_curated_csv: "data/03_gold_standard/gold_standard_full.csv" 
    
    # Artefactos generados por `prepare_evaluation_sets.py` para entrenamiento y test.
    train_csv: "data/03_gold_standard/gold_standard_train.csv" 
    test_csv: "data/03_gold_standard/gold_standard_test.csv" 
    train_jsonl: "data/03_gold_standard/gold_standard_train.jsonl" 
    test_jsonl: "data/03_gold_standard/gold_standard_test.jsonl" 

# --- Parámetros para la División de Datos --- 
# Usado por `scripts/prepare_evaluation_sets.py`
data_split:
  test_size: 0.20 # Proporción del Golden Set que se reserva como conjunto de test "sagrado".
  stratify_column: 'category' # Asegura que la distribución de categorías sea igual en train y test.

# --- Rutas a los Artefactos de Salida ---
output_paths:
  reports: "outputs/reports"
  # Archivos CSV detallados generados durante la evaluación para un análisis de errores posterior.
  eval_results:
    student_baseline: "outputs/reports/student_baseline_results.csv"
    teacher_candidate: "outputs/reports/teacher_results.csv"

# --- Parámetros de Modelos y Prompts ---
teacher_model:
  # IMPORTANTE: Usar el ID oficial del modelo del proveedor para reproducibilidad.
  # Ejemplo: "gemini-1.5-pro-latest"
  model_name: "gemini-1.5-pro-latest" # <-- REVISAR Y ACTUALIZAR
  # Temperatura baja para que el Teacher sea lo más determinista y consistente posible.
  # En la fase de generación de datos, no buscamos creatividad, sino precisión.
  temperature: 0.2
  prompt_id: "P-07_zero_shot_gemini_friendly"

student_model:
  base_model_name: "Qwen/Qwen3-4B-Instruct-2507"
  prompt_id: "S-03_student_silver_bullet" 
  output_dir: "models/distilmatch_qwen_lora_v1"

# --- Parámetros de los Pasos del Pipeline ---
silver_set_generation:
  # Se toma el valor de data_paths.intermediate.silver_standard_train para consistencia.
  num_samples_to_generate: 9000
  # Delay entre llamadas a la API. Crucial para no exceder los límites de la cuenta.
  # 12 para Free Tier (5 RPM), ~0.5 para Paid Tier (>120 RPM).
  delay_between_requests_sec: 0.0 # Ajustado para la versión con multiprocessing
  max_words_per_field: 600 # Trunca los textos de CV y oferta para evitar exceder el límite de contexto del modelo.

training:
  num_epochs: 3
  learning_rate: 2e-5
  batch_size: 16
  # Reservamos una pequeña parte del dataset de entrenamiento para monitorizar el sobreajuste.
  validation_split_size: 0.1 

active_learning:
  # El rango de scores donde el modelo es más "dudoso", ideal para que un humano anote.
  uncertainty_threshold_low: 50.0
  uncertainty_threshold_high: 70.0
  selection_batch_size: 100 # Número de muestras a anotar en cada ciclo.

  # --- GESTIÓN DE EXPERIMENTOS ---
# Cada entrada aquí define un ciclo completo de entrenamiento y evaluación.
# Esto nos permite comparar diferentes enfoques de forma limpia y reproducible.
experiments:

  score_only_v1:
    description: "Fine-tuning solo para predecir el score numérico. Sufrió colapso de modo."
    training:
      enabled: true # Permite saltarse el re-entrenamiento si ya está hecho
      num_epochs: 3
      learning_rate: 2e-5
      batch_size: 8 # Ajustado a un valor más común para LoRA
      validation_split_size: 0.1
      run_name: "distilmatch_v1_score_only" # Nombre para wandb
    output_dir: "distilmatch_qwen_lora_v1_score_only" # Se guardará dentro de output_paths.models_dir
    evaluation_output_csv: "eval_results_v1_score_only.csv" # Se guardará en output_paths.reports

  
  reasoning_v2:
    description: "Explanation-Tuning: Se entrena para generar el razonamiento completo."
    training:
      enabled: true
      num_epochs: 3
      learning_rate: 2e-5
      batch_size: 8
      validation_split_size: 0.1
      run_name: "distilmatch_v2_reasoning"
    output_dir: "distilmatch_qwen_lora_v2_reasoning"
    evaluation_output_csv: "eval_results_v2_reasoning.csv"