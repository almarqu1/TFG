# =================================================================
# FICHERO DE CONFIGURACIÓN GLOBAL DEL PROYECTO DISTILMATCH
# Centraliza todas las rutas, hiperparámetros y constantes para
# garantizar la reproducibilidad y facilitar la experimentación.
# =================================================================

# --- Parámetros Globales ---
global_seed: 42  # Semilla para todas las operaciones aleatorias (división de datos, muestreo).
                 # Fundamental para garantizar que los experimentos sean 100% reproducibles.

# --- Rutas del Pipeline de Datos (MLOps Staging) ---
# Estructura inspirada en las mejores prácticas de MLOps, separando los datos por su etapa
# de procesamiento para mantener un flujo de trabajo claro y versionable con DVC.
data_paths:
  # 00_raw: Datos originales, tal como se reciben. Son de solo lectura.
  raw:
    offers: "data/00_raw/datasetJobs2/postings.csv"
    job_skills: "data/00_raw/datasetJobs2/jobs/job_skills.csv"
    skills_map: "data/00_raw/datasetJobs2/mappings/skills.csv"
    job_industries: "data/00_raw/datasetJobs2/jobs/job_industries.csv"
    industries_map: "data/00_raw/datasetJobs2/mappings/industries.csv"
    cvs: "data/00_raw/datasetCV2/resume_data.csv"
  
  # 01_processed: Datos limpios y enriquecidos, listos para ser consumidos por los scripts.
  processed:
    offers: "data/01_processed/offers_processed.csv"
    cvs: "data/01_processed/cvs_processed.csv"
    # Este archivo contiene los pares aleatorios CV-Oferta que alimentarán al Teacher.
    unlabeled_pairs: "data/01_processed/unlabeled_pairs.csv"   
  
  # 02_intermediate: Artefactos generados que sirven como 'pegamento' entre etapas.
  intermediate:
    # El "Silver Set": un gran corpus de datos etiquetados por el Teacher (soft labels)
    # que se usará para el fine-tuning del modelo Student.
    silver_standard_train: "data/02_intermediate/silver_standard_train.jsonl"
  
  # 03_gold_standard: La "verdad absoluta" del proyecto. Curado manualmente por el experto.
  gold_standard:
    # El archivo de entrada completo, producto de la herramienta de curación.
    full_curated_csv: "data/03_gold_standard/gold_standard_full.csv" 
    
    # Artefactos generados por `prepare_evaluation_sets.py` para entrenamiento y test.
    train_csv: "data/03_gold_standard/gold_standard_train.csv" 
    test_csv: "data/03_gold_standard/gold_standard_test.csv" 
    train_jsonl: "data/03_gold_standard/gold_standard_train.jsonl" 
    test_jsonl: "data/03_gold_standard/gold_standard_test.jsonl" 

# --- Parámetros para la División de Datos --- 
# Usado por `scripts/prepare_evaluation_sets.py`
data_split:
  test_size: 0.20 # Proporción del Golden Set que se reserva como conjunto de test "sagrado".
  stratify_column: 'category' # Asegura que la distribución de categorías sea igual en train y test.

# --- Rutas a los Artefactos de Salida ---
output_paths:
  reports: "outputs/reports"
  # Archivos CSV detallados generados durante la evaluación para un análisis de errores posterior.
  eval_results:
    student_baseline: "outputs/reports/student_baseline_results.csv"
    teacher_candidate: "outputs/reports/teacher_results.csv"

# --- Parámetros de Modelos y Prompts ---
teacher_model:
  # IMPORTANTE: Usar el ID oficial del modelo del proveedor para reproducibilidad.
  # Ejemplo: "gemini-1.5-pro-latest"
  model_name: "gemini-1.5-pro-latest" # <-- REVISAR Y ACTUALIZAR
  # Temperatura baja para que el Teacher sea lo más determinista y consistente posible.
  # En la fase de generación de datos, no buscamos creatividad, sino precisión.
  temperature: 0.2
  prompt_id: "P-07_zero_shot_gemini_friendly"

student_model:
  base_model_name: "Qwen/Qwen3-4B-Instruct-2507"
  prompt_id: "S-03_student_silver_bullet" 
  output_dir: "models/distilmatch_qwen_lora_v1"

# --- Parámetros de los Pasos del Pipeline ---
silver_set_generation:
  # Se toma el valor de data_paths.intermediate.silver_standard_train para consistencia.
  num_samples_to_generate: 9000
  # Delay entre llamadas a la API. Crucial para no exceder los límites de la cuenta.
  # 12 para Free Tier (5 RPM), ~0.5 para Paid Tier (>120 RPM).
  delay_between_requests_sec: 0.0 # Ajustado para la versión con multiprocessing
  max_words_per_field: 600 # Trunca los textos de CV y oferta para evitar exceder el límite de contexto del modelo.

training:
  num_epochs: 3
  learning_rate: 2e-5
  batch_size: 16
  # Reservamos una pequeña parte del dataset de entrenamiento para monitorizar el sobreajuste.
  validation_split_size: 0.1 

active_learning:
  # El rango de scores donde el modelo es más "dudoso", ideal para que un humano anote.
  uncertainty_threshold_low: 50.0
  uncertainty_threshold_high: 70.0
  selection_batch_size: 100 # Número de muestras a anotar en cada ciclo.

  # --- GESTIÓN DE EXPERIMENTOS ---
experiments:
  # Experimento Base (fallido) - Lo mantenemos como referencia
  v1_silver_unbalanced:
    description: "Score-Only con Silver Set desequilibrado. Sirve como baseline de 'qué no hacer'."
    dataset_path: "data/02_intermediate/silver_standard_train.jsonl"
    training_params:
      num_epochs: 3
      learning_rate: 2e-5
      batch_size: 16
    output_dir: "models/distilmatch_qwen_lora_v1"
    run_name: "distilmatch_qwen_lora_v1"

  # Experimento con Golden Set (Calidad > Cantidad)
  v2_gold_only:
    description: "Fine-tuning directo solo con el Golden Set (train). Prueba de 'calidad sobre cantidad'."
    dataset_path: "data/03_gold_standard/gold_standard_train.jsonl"
    training_params:
      num_epochs: 8 # Más épocas porque el dataset es pequeño
      learning_rate: 2e-5
      batch_size: 4 # Batch size más pequeño
    output_dir: "models/distilmatch_v2_gold_only"
    run_name: "distilmatch_v2_gold_only"

  # Experimento con Silver Set Balanceado (Cantidad con Calidad)
  v3_silver_balanced:
    description: "Knowledge Distillation con Silver Set balanceado. Prueba de 'cantidad con calidad'."
    dataset_path: "data/02_intermediate/silver_standard_train_balanced.jsonl"
    training_params:
      num_epochs: 4 # Un poco más de épocas que el v1
      learning_rate: 2e-5
      batch_size: 16
    output_dir: "models/distilmatch_v3_silver_balanced"
    run_name: "distilmatch_v3_silver_balanced"

  v4_silver_balanced_reasoning:
      description: "KD con Silver Set balanceado, entrenado para generar el razonamiento completo."
      dataset_path: "data/02_intermediate/silver_standard_train_balanced.jsonl"
      prompt_id: "S-04_student_reasoning_structured"
      training_params:
        num_epochs: 4
        learning_rate: 2e-5
        batch_size: 8 # Usamos un batch size más pequeño porque el texto es más largo
      output_dir: "models/distilmatch_v4_silver_balanced_reasoning"
      run_name: "distilmatch_v4_silver_balanced_reasoning"

  v5_silver_reasoning:
      description: "KD con Silver Set desequilibrado, entrenado para generar el razonamiento completo."
      dataset_path: "data/02_intermediate/silver_standard_train.jsonl"
      prompt_id: "S-04_student_reasoning_structured"
      training_params:
        num_epochs: 4
        learning_rate: 2e-5
        batch_size: 8 # Usamos un batch size más pequeño porque el texto es más largo
      output_dir: "models/distilmatch_v4_silver_balanced_reasoning"
      run_name: "distilmatch_v4_silver_balanced_reasoning"